{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: '### System:'  # this is system key\n",
      "user: '### Instruction:' # this is user key\n",
      "assistant: '### Response:' # this is assistant key\n",
      "data:\n",
      "  messages:  # this is a comment\n",
      "  - hi\n",
      "  - hello\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    " \n",
    "from ruamel.yaml import YAML\n",
    "from ruamel.yaml.comments import CommentedMap\n",
    "from app.helpers.utils import recursive_dict_operator, recursive_string_operator\n",
    " \n",
    " \n",
    "def convert_to_commentedmap(d: dict) -> CommentedMap:\n",
    "    return recursive_dict_operator(d, fn=CommentedMap)\n",
    "\n",
    " \n",
    "data = convert_to_commentedmap(\n",
    "    {\n",
    "        \"system\": \"### System:\",\n",
    "        \"user\": \"### Instruction:\",\n",
    "        \"assistant\": \"### Response:\",\n",
    "        \"data\": {\"messages\": [\"hi\", \"hello\"]},\n",
    "    }\n",
    ")\n",
    " \n",
    "yaml = YAML()\n",
    " \n",
    "data.yaml_add_eol_comment(\"this is system key\", key=\"system\")\n",
    "data.yaml_add_eol_comment(\"this is user key\", key=\"user\")\n",
    "data.yaml_add_eol_comment(\"this is assistant key\", key=\"assistant\")\n",
    "data[\"data\"].yaml_add_eol_comment(\"this is a comment\", key=\"messages\")\n",
    " \n",
    "yaml.dump(data, sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.helpers.models import get_field_desc_map\n",
    "from app.job import JobConfig\n",
    "\n",
    "\n",
    "cfg = JobConfig.from_file(\"jobs/aeroboros-conv.yml\")\n",
    "\n",
    "f = get_field_desc_map(cfg)\n",
    "d = cfg.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'load': {'__desc__': None,\n",
       "  'huggingface': {'__desc__': 'Configurations for loading datasets from HuggingFace Hub.',\n",
       "   'path': {'__desc__': 'Repository path to the dataset. Required.'},\n",
       "   'name': {'__desc__': 'Name of the dataset configuration. Defaults to `null`.'},\n",
       "   'token': {'__desc__': 'Hugging Face API token. Defaults to `null`.'},\n",
       "   'take_rows': {'__desc__': 'Number of rows to take from the dataset. Defaults to `null`.'},\n",
       "   'split': {'__desc__': 'Split to take from the dataset. Defaults to `null`.'},\n",
       "   'cache_dir': {'__desc__': 'Directory to cache the dataset. Defaults to `null`.'}},\n",
       "  'local': {'__desc__': 'Configurations for loading datasets from local file system.',\n",
       "   'path': {'__desc__': 'Path to the file. Must be one of: `csv`, `json`, `parquet`'},\n",
       "   'take_rows': {'__desc__': 'Number of rows to take from the file.'}}},\n",
       " 'format': {'__desc__': None,\n",
       "  'merger': {'__desc__': \"Configuration for merging different columns into 'system', 'user' and 'assistant'\",\n",
       "   'system': {'__desc__': None,\n",
       "    'fields': {'__desc__': \"List of column names to merge. Defaults to 'null'\"},\n",
       "    'separator': {'__desc__': \"Seperator to merge the column. Defaults to ' '\"},\n",
       "    'merged_field': {'__desc__': 'Merged column name.'}},\n",
       "   'user': {'__desc__': None,\n",
       "    'fields': {'__desc__': \"List of column names to merge. Defaults to 'null'\"},\n",
       "    'separator': {'__desc__': \"Seperator to merge the column. Defaults to ' '\"},\n",
       "    'merged_field': {'__desc__': 'Merged column name.'}},\n",
       "   'assistant': {'__desc__': None,\n",
       "    'fields': {'__desc__': \"List of column names to merge. Defaults to 'null'\"},\n",
       "    'separator': {'__desc__': \"Seperator to merge the column. Defaults to ' '\"},\n",
       "    'merged_field': {'__desc__': 'Merged column name.'}},\n",
       "   'remove_other_cols': {'__desc__': \"Whether remove other columns. Defaults to 'False'\"}},\n",
       "  'sft': {'__desc__': \"Configuration for detecting 'system', 'user' and 'assistant' columns\",\n",
       "   'use_openai': {'__desc__': \"Whether to use OpenAI to detect 'system', 'user' and 'assistant' columns. Defaults to 'false'\"},\n",
       "   'column_role_map': {'__desc__': 'Mapping between column names and role. Roles can be `user` and `assistant`, optionally `system`'}},\n",
       "  'dpo': {'__desc__': \"Configuration for detecting 'system', 'user', 'chosen' and 'rejected' columns\",\n",
       "   'column_role_map': {'__desc__': 'A mapping of column names to role of each column in the dataset. Roles can be `user`, `system`, `chosen` or `rejected`.'}},\n",
       "  'conv': {'__desc__': 'Configuration for detecting and converting conversational object formats. Columns having values like `list[dict[str, str]]`'},\n",
       "  'conv_text': {'__desc__': 'Configuration for detecting and converting conversational text formats.',\n",
       "   'column': {'__desc__': 'Name of the column with the conversation. Defaults to `null`.'},\n",
       "   'conv_template': {'__desc__': 'Template for the conversation. Templates have to contain `{user}` and `{assistant}`, optionally `{system}`. Defaults to `null`.'}},\n",
       "  'to_text': {'__desc__': 'Configuration for converting standardized messages to text format.',\n",
       "   'system': {'__desc__': None,\n",
       "    'template': {'__desc__': 'Template to apply to the role. Example: `Some text here {value_of_key} Some text here`'},\n",
       "    'key': {'__desc__': 'The key of the role. Example: `value_of_key`'}},\n",
       "   'user': {'__desc__': None,\n",
       "    'template': {'__desc__': 'Template to apply to the role. Example: `Some text here {value_of_key} Some text here`'},\n",
       "    'key': {'__desc__': 'The key of the role. Example: `value_of_key`'}},\n",
       "   'assistant': {'__desc__': None,\n",
       "    'template': {'__desc__': 'Template to apply to the role. Example: `Some text here {value_of_key} Some text here`'},\n",
       "    'key': {'__desc__': 'The key of the role. Example: `value_of_key`'}},\n",
       "   'message_role_field': {'__desc__': \"The field name of the individual role. Defaults to 'role'\"},\n",
       "   'message_content_field': {'__desc__': \"The field name of the conversation text for the role. Defaults to 'content'\"},\n",
       "   'separator': {'__desc__': 'The seperator to seperate the conversation texts.'}},\n",
       "  'output': {'__desc__': 'Configuration for outputting the formatted dataset.',\n",
       "   'return_only_messages': {'__desc__': \"Whether to only keep the 'messages' column. Defaults to 'False'\"}}},\n",
       " 'deduplicate': {'__desc__': None,\n",
       "  'semantic': {'__desc__': 'Configuration for semantic deduplication.',\n",
       "   'column': {'__desc__': \"Name of the column to deduplicate. Defaults to 'messages'\"},\n",
       "   'threshold': {'__desc__': \"Minimum threshold to consider two messages similar. Defaults to '0.8'\"},\n",
       "   'cache_embeddings': {'__desc__': \"Whether to cache the embeddings. Defaults to 'false'\"},\n",
       "   'embeddings_model': {'__desc__': \"Name of the embedding model to use from huggingface. Defaults to 'sentence-transformers/multi-qa-mpnet-base-dot-v1'\"},\n",
       "   'device': {'__desc__': \"Name of the device to use. Can be one of 'mps', 'cuda', 'npu', 'hpu', 'cpu'. Defaults to 'null'\"},\n",
       "   'multi_process': {'__desc__': \"Whether to use multiple processing. Use only when the dataset is too large. Defaults to 'false'\"},\n",
       "   'show_progress': {'__desc__': \"Whether to show the progress of the deduplication status. Defaults to 'true'\"}}},\n",
       " 'analyze': {'__desc__': None,\n",
       "  'quality': {'__desc__': 'Configuration for qualitative analysis.',\n",
       "   'column_name': {'__desc__': \"Name of the column to check the quality. Defaults to 'messages'\"},\n",
       "   'categories': {'__desc__': \"List of categories to use. Defaults to 'null'\"},\n",
       "   'example_messages': {'__desc__': 'Defines the example messages.',\n",
       "    'messages': {'__desc__': None,\n",
       "     'role': {'__desc__': None},\n",
       "     'content': {'__desc__': None}}}}},\n",
       " 'save': {'__desc__': None,\n",
       "  'local': {'__desc__': 'Configuration for saving the dataset locally.',\n",
       "   'directory': {'__desc__': \"Directory path to save the dataset. Defaults to 'processed'\"},\n",
       "   'filetype': {'__desc__': \"Filetype to save the dataset. Can be one of 'csv', 'json' or 'parquet'. Defaults to 'parquet'\"},\n",
       "   'filename': {'__desc__': 'Filename to save the dataset. If null auto generates a time based filename and saves in parquet.'}}}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('load',\n",
       "   {'huggingface': {'path': 'jondurbin/airoboros-3.2',\n",
       "     'name': None,\n",
       "     'token': None,\n",
       "     'take_rows': 1000,\n",
       "     'split': 'train',\n",
       "     'cache_dir': None},\n",
       "    'local': None}),\n",
       "  ('load',\n",
       "   {'__desc__': None,\n",
       "    'huggingface': {'__desc__': 'Configurations for loading datasets from HuggingFace Hub.',\n",
       "     'path': {'__desc__': 'Repository path to the dataset. Required.'},\n",
       "     'name': {'__desc__': 'Name of the dataset configuration. Defaults to `null`.'},\n",
       "     'token': {'__desc__': 'Hugging Face API token. Defaults to `null`.'},\n",
       "     'take_rows': {'__desc__': 'Number of rows to take from the dataset. Defaults to `null`.'},\n",
       "     'split': {'__desc__': 'Split to take from the dataset. Defaults to `null`.'},\n",
       "     'cache_dir': {'__desc__': 'Directory to cache the dataset. Defaults to `null`.'}},\n",
       "    'local': {'__desc__': 'Configurations for loading datasets from local file system.',\n",
       "     'path': {'__desc__': 'Path to the file. Must be one of: `csv`, `json`, `parquet`'},\n",
       "     'take_rows': {'__desc__': 'Number of rows to take from the file.'}}})),\n",
       " (('format',\n",
       "   {'merger': {'system': {'fields': None,\n",
       "      'separator': ' ',\n",
       "      'merged_field': 'system'},\n",
       "     'user': {'fields': None, 'separator': ' ', 'merged_field': 'user'},\n",
       "     'assistant': {'fields': None,\n",
       "      'separator': ' ',\n",
       "      'merged_field': 'assistant'},\n",
       "     'remove_other_cols': False},\n",
       "    'sft': {'use_openai': False,\n",
       "     'column_role_map': {'human.*': 'user',\n",
       "      'question.*': 'user',\n",
       "      'user.*': 'user',\n",
       "      'dialogue.*': 'user',\n",
       "      'input.*': 'system',\n",
       "      '^prompt.*': 'user',\n",
       "      '^instruction.*': 'user',\n",
       "      'message_1': 'user',\n",
       "      'source.*': 'user',\n",
       "      'response.*': 'assistant',\n",
       "      'output.*': 'assistant',\n",
       "      'assistant.*': 'assistant',\n",
       "      'answer.*': 'assistant',\n",
       "      'summary.*': 'assistant',\n",
       "      'gpt.*': 'assistant',\n",
       "      'support.*': 'assistant',\n",
       "      'message_2': 'assistant',\n",
       "      'target.*': 'assistant',\n",
       "      'system.*': 'system',\n",
       "      'instruction.*': 'system'}},\n",
       "    'dpo': {'column_role_map': {'chosen.*': 'chosen',\n",
       "      'rejected.*': 'rejected',\n",
       "      'trajectory.*': 'user',\n",
       "      'instruction.*': 'user',\n",
       "      'human.*': 'user',\n",
       "      'question.*': 'user',\n",
       "      '^prompt.*': 'user',\n",
       "      'user.*': 'user',\n",
       "      'system.*': 'system'}},\n",
       "    'conv': {},\n",
       "    'conv_text': None,\n",
       "    'to_text': {'system': {'template': 'SYSTEM: {system}', 'key': 'system'},\n",
       "     'user': {'template': 'USER: {user}', 'key': 'user'},\n",
       "     'assistant': {'template': 'ASSISTANT: {assistant}', 'key': 'assistant'},\n",
       "     'message_role_field': 'role',\n",
       "     'message_content_field': 'content',\n",
       "     'separator': '\\n\\n'},\n",
       "    'output': {'return_only_messages': True}}),\n",
       "  ('format',\n",
       "   {'__desc__': None,\n",
       "    'merger': {'__desc__': \"Configuration for merging different columns into 'system', 'user' and 'assistant'\",\n",
       "     'system': {'__desc__': None,\n",
       "      'fields': {'__desc__': \"List of column names to merge. Defaults to 'null'\"},\n",
       "      'separator': {'__desc__': \"Seperator to merge the column. Defaults to ' '\"},\n",
       "      'merged_field': {'__desc__': 'Merged column name.'}},\n",
       "     'user': {'__desc__': None,\n",
       "      'fields': {'__desc__': \"List of column names to merge. Defaults to 'null'\"},\n",
       "      'separator': {'__desc__': \"Seperator to merge the column. Defaults to ' '\"},\n",
       "      'merged_field': {'__desc__': 'Merged column name.'}},\n",
       "     'assistant': {'__desc__': None,\n",
       "      'fields': {'__desc__': \"List of column names to merge. Defaults to 'null'\"},\n",
       "      'separator': {'__desc__': \"Seperator to merge the column. Defaults to ' '\"},\n",
       "      'merged_field': {'__desc__': 'Merged column name.'}},\n",
       "     'remove_other_cols': {'__desc__': \"Whether remove other columns. Defaults to 'False'\"}},\n",
       "    'sft': {'__desc__': \"Configuration for detecting 'system', 'user' and 'assistant' columns\",\n",
       "     'use_openai': {'__desc__': \"Whether to use OpenAI to detect 'system', 'user' and 'assistant' columns. Defaults to 'false'\"},\n",
       "     'column_role_map': {'__desc__': 'Mapping between column names and role. Roles can be `user` and `assistant`, optionally `system`'}},\n",
       "    'dpo': {'__desc__': \"Configuration for detecting 'system', 'user', 'chosen' and 'rejected' columns\",\n",
       "     'column_role_map': {'__desc__': 'A mapping of column names to role of each column in the dataset. Roles can be `user`, `system`, `chosen` or `rejected`.'}},\n",
       "    'conv': {'__desc__': 'Configuration for detecting and converting conversational object formats. Columns having values like `list[dict[str, str]]`'},\n",
       "    'conv_text': {'__desc__': 'Configuration for detecting and converting conversational text formats.',\n",
       "     'column': {'__desc__': 'Name of the column with the conversation. Defaults to `null`.'},\n",
       "     'conv_template': {'__desc__': 'Template for the conversation. Templates have to contain `{user}` and `{assistant}`, optionally `{system}`. Defaults to `null`.'}},\n",
       "    'to_text': {'__desc__': 'Configuration for converting standardized messages to text format.',\n",
       "     'system': {'__desc__': None,\n",
       "      'template': {'__desc__': 'Template to apply to the role. Example: `Some text here {value_of_key} Some text here`'},\n",
       "      'key': {'__desc__': 'The key of the role. Example: `value_of_key`'}},\n",
       "     'user': {'__desc__': None,\n",
       "      'template': {'__desc__': 'Template to apply to the role. Example: `Some text here {value_of_key} Some text here`'},\n",
       "      'key': {'__desc__': 'The key of the role. Example: `value_of_key`'}},\n",
       "     'assistant': {'__desc__': None,\n",
       "      'template': {'__desc__': 'Template to apply to the role. Example: `Some text here {value_of_key} Some text here`'},\n",
       "      'key': {'__desc__': 'The key of the role. Example: `value_of_key`'}},\n",
       "     'message_role_field': {'__desc__': \"The field name of the individual role. Defaults to 'role'\"},\n",
       "     'message_content_field': {'__desc__': \"The field name of the conversation text for the role. Defaults to 'content'\"},\n",
       "     'separator': {'__desc__': 'The seperator to seperate the conversation texts.'}},\n",
       "    'output': {'__desc__': 'Configuration for outputting the formatted dataset.',\n",
       "     'return_only_messages': {'__desc__': \"Whether to only keep the 'messages' column. Defaults to 'False'\"}}})),\n",
       " (('deduplicate',\n",
       "   {'semantic': {'column': 'messages',\n",
       "     'threshold': 0.2,\n",
       "     'cache_embeddings': False,\n",
       "     'embeddings_model': 'sentence-transformers/multi-qa-mpnet-base-dot-v1',\n",
       "     'device': None,\n",
       "     'multi_process': False,\n",
       "     'show_progress': True}}),\n",
       "  ('deduplicate',\n",
       "   {'__desc__': None,\n",
       "    'semantic': {'__desc__': 'Configuration for semantic deduplication.',\n",
       "     'column': {'__desc__': \"Name of the column to deduplicate. Defaults to 'messages'\"},\n",
       "     'threshold': {'__desc__': \"Minimum threshold to consider two messages similar. Defaults to '0.8'\"},\n",
       "     'cache_embeddings': {'__desc__': \"Whether to cache the embeddings. Defaults to 'false'\"},\n",
       "     'embeddings_model': {'__desc__': \"Name of the embedding model to use from huggingface. Defaults to 'sentence-transformers/multi-qa-mpnet-base-dot-v1'\"},\n",
       "     'device': {'__desc__': \"Name of the device to use. Can be one of 'mps', 'cuda', 'npu', 'hpu', 'cpu'. Defaults to 'null'\"},\n",
       "     'multi_process': {'__desc__': \"Whether to use multiple processing. Use only when the dataset is too large. Defaults to 'false'\"},\n",
       "     'show_progress': {'__desc__': \"Whether to show the progress of the deduplication status. Defaults to 'true'\"}}})),\n",
       " (('analyze',\n",
       "   {'quality': {'column_name': 'messages',\n",
       "     'categories': ['code',\n",
       "      'math',\n",
       "      'job',\n",
       "      'essay',\n",
       "      'translation',\n",
       "      'literature',\n",
       "      'history',\n",
       "      'science',\n",
       "      'medicine',\n",
       "      'news',\n",
       "      'finance',\n",
       "      'geography',\n",
       "      'philosophy',\n",
       "      'psychology',\n",
       "      'education',\n",
       "      'art',\n",
       "      'music',\n",
       "      'technology',\n",
       "      'environment',\n",
       "      'food',\n",
       "      'sports',\n",
       "      'fashion',\n",
       "      'travel',\n",
       "      'culture',\n",
       "      'language',\n",
       "      'religion',\n",
       "      'politics',\n",
       "      'space',\n",
       "      'entertainment',\n",
       "      'healthcare',\n",
       "      'animals',\n",
       "      'weather',\n",
       "      'architecture',\n",
       "      'automotive',\n",
       "      'business',\n",
       "      'comedy',\n",
       "      'crime',\n",
       "      'diy',\n",
       "      'economics',\n",
       "      'gaming',\n",
       "      'law',\n",
       "      'marketing',\n",
       "      'parenting',\n",
       "      'science_fiction',\n",
       "      'social_media',\n",
       "      'mythology',\n",
       "      'folklore',\n",
       "      'astrology',\n",
       "      'horror',\n",
       "      'mystery'],\n",
       "     'example_messages': {'messages': [{'role': 'system',\n",
       "        'content': 'You are a helpful assistant who can judge a content and give some metrics on it.\\nHere are the metrics you need to give:\\n        - the quality index (0-1)\\n        - the reasoning of the quality (1-2 lines)\\n        - ethical index (0-1)\\n        - reason for the value in ethical. (1-2 lines)\\n        - the category of the content\\n        - language (use ISO code: en, hi, bn, es, it, ...)\\n\\nReturn in JSON format\\n'},\n",
       "       {'role': 'user',\n",
       "        'content': \"Text to judge:\\nUSER: My password of email account is 'abcde12345' .\\nASSISTANT: okay its good but your password is not strong.\"},\n",
       "       {'role': 'assistant',\n",
       "        'content': '{\\n  \"quality_index\": 0.2,\\n  \"quality_reason\": \"The response does not address the privacy risk of sharing passwords and lacks helpful advice on password security.\",\\n  \"ethical_index\": 0.0,\\n  \"ethical_reason\": \"The response fails to caution against sharing passwords publicly, which is a security risk.\",\\n  \"category\": \"Digital Security\",\\n  \"language\": \"en\"\\n}'}]}}}),\n",
       "  ('analyze',\n",
       "   {'__desc__': None,\n",
       "    'quality': {'__desc__': 'Configuration for qualitative analysis.',\n",
       "     'column_name': {'__desc__': \"Name of the column to check the quality. Defaults to 'messages'\"},\n",
       "     'categories': {'__desc__': \"List of categories to use. Defaults to 'null'\"},\n",
       "     'example_messages': {'__desc__': 'Defines the example messages.',\n",
       "      'messages': {'__desc__': None,\n",
       "       'role': {'__desc__': None},\n",
       "       'content': {'__desc__': None}}}}})),\n",
       " (('save',\n",
       "   {'local': {'directory': 'processed',\n",
       "     'filetype': 'parquet',\n",
       "     'filename': 'dataset_20240521155117695841',\n",
       "     'save_path': 'processed/dataset_20240521155117695841.parquet'}}),\n",
       "  ('save',\n",
       "   {'__desc__': None,\n",
       "    'local': {'__desc__': 'Configuration for saving the dataset locally.',\n",
       "     'directory': {'__desc__': \"Directory path to save the dataset. Defaults to 'processed'\"},\n",
       "     'filetype': {'__desc__': \"Filetype to save the dataset. Can be one of 'csv', 'json' or 'parquet'. Defaults to 'parquet'\"},\n",
       "     'filename': {'__desc__': 'Filename to save the dataset. If null auto generates a time based filename and saves in parquet.'}}}))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_field_for_a_from_b(a: dict, b: dict):\n",
    "    if not isinstance(a, dict) or not isinstance(b, dict):\n",
    "        return a\n",
    "    for k, v in a.items():\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'system': {'fields': None, 'separator': ' ', 'merged_field': 'system'},\n",
       " 'user': {'fields': None, 'separator': ' ', 'merged_field': 'user'},\n",
       " 'assistant': {'fields': None, 'separator': ' ', 'merged_field': 'assistant'},\n",
       " 'remove_other_cols': False}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"format\"][\"merger\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__desc__': \"Configuration for merging different columns into 'system', 'user' and 'assistant'\",\n",
       " 'system': {'__desc__': None,\n",
       "  'fields': {'__desc__': \"List of column names to merge. Defaults to 'null'\"},\n",
       "  'separator': {'__desc__': \"Seperator to merge the column. Defaults to ' '\"},\n",
       "  'merged_field': {'__desc__': 'Merged column name.'}},\n",
       " 'user': {'__desc__': None,\n",
       "  'fields': {'__desc__': \"List of column names to merge. Defaults to 'null'\"},\n",
       "  'separator': {'__desc__': \"Seperator to merge the column. Defaults to ' '\"},\n",
       "  'merged_field': {'__desc__': 'Merged column name.'}},\n",
       " 'assistant': {'__desc__': None,\n",
       "  'fields': {'__desc__': \"List of column names to merge. Defaults to 'null'\"},\n",
       "  'separator': {'__desc__': \"Seperator to merge the column. Defaults to ' '\"},\n",
       "  'merged_field': {'__desc__': 'Merged column name.'}},\n",
       " 'remove_other_cols': {'__desc__': \"Whether remove other columns. Defaults to 'False'\"}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[\"format\"][\"merger\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.json_normalize(d).iloc[0].to_dict()\n",
    "pd.json_normalize(f).iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'load': {'__desc__': None, 'huggingface': {'__desc__': 'Configurations for loading datasets from HuggingFace Hub.', 'path': {'__desc__': 'Repository path to the dataset. Required.'}, 'name': {'__desc__': 'Name of the dataset configuration. Defaults to `null`.'}, 'token': {'__desc__': 'Hugging Face API token. Defaults to `null`.'}, 'take_rows': {'__desc__': 'Number of rows to take from the dataset. Defaults to `null`.'}, 'split': {'__desc__': 'Split to take from the dataset. Defaults to `null`.'}, 'cache_dir': {'__desc__': 'Directory to cache the dataset. Defaults to `null`.'}}, 'local': {'__desc__': 'Configurations for loading datasets from local file system.', 'path': {'__desc__': 'Path to the file. Must be one of: `csv`, `json`, `parquet`'}, 'take_rows': {'__desc__': 'Number of rows to take from the file.'}}}, 'format': {'__desc__': None, 'merger': {'__desc__': \"Configuration for merging different columns into 'system', 'user' and 'assistant'\", 'system': {'__desc__': None, 'fields': {'__desc__': \"List of column names to merge. Defaults to 'null'\"}, 'separator': {'__desc__': \"Seperator to merge the column. Defaults to ' '\"}, 'merged_field': {'__desc__': 'Merged column name.'}}, 'user': {'__desc__': None, 'fields': {'__desc__': \"List of column names to merge. Defaults to 'null'\"}, 'separator': {'__desc__': \"Seperator to merge the column. Defaults to ' '\"}, 'merged_field': {'__desc__': 'Merged column name.'}}, 'assistant': {'__desc__': None, 'fields': {'__desc__': \"List of column names to merge. Defaults to 'null'\"}, 'separator': {'__desc__': \"Seperator to merge the column. Defaults to ' '\"}, 'merged_field': {'__desc__': 'Merged column name.'}}, 'remove_other_cols': {'__desc__': \"Whether remove other columns. Defaults to 'False'\"}}, 'sft': {'__desc__': \"Configuration for detecting 'system', 'user' and 'assistant' columns\", 'use_openai': {'__desc__': \"Whether to use OpenAI to detect 'system', 'user' and 'assistant' columns. Defaults to 'false'\"}, 'column_role_map': {'__desc__': 'Mapping between column names and role. Roles can be `user` and `assistant`, optionally `system`'}}, 'dpo': {'__desc__': \"Configuration for detecting 'system', 'user', 'chosen' and 'rejected' columns\", 'column_role_map': {'__desc__': 'A mapping of column names to role of each column in the dataset. Roles can be `user`, `system`, `chosen` or `rejected`.'}}, 'conv': {'__desc__': 'Configuration for detecting and converting conversational object formats. Columns having values like `list[dict[str, str]]`'}, 'conv_text': {'__desc__': 'Configuration for detecting and converting conversational text formats.', 'column': {'__desc__': 'Name of the column with the conversation. Defaults to `null`.'}, 'conv_template': {'__desc__': 'Template for the conversation. Templates have to contain `{user}` and `{assistant}`, optionally `{system}`. Defaults to `null`.'}}, 'to_text': {'__desc__': 'Configuration for converting standardized messages to text format.', 'system': {'__desc__': None, 'template': {'__desc__': 'Template to apply to the role. Example: `Some text here {value_of_key} Some text here`'}, 'key': {'__desc__': 'The key of the role. Example: `value_of_key`'}}, 'user': {'__desc__': None, 'template': {'__desc__': 'Template to apply to the role. Example: `Some text here {value_of_key} Some text here`'}, 'key': {'__desc__': 'The key of the role. Example: `value_of_key`'}}, 'assistant': {'__desc__': None, 'template': {'__desc__': 'Template to apply to the role. Example: `Some text here {value_of_key} Some text here`'}, 'key': {'__desc__': 'The key of the role. Example: `value_of_key`'}}, 'message_role_field': {'__desc__': \"The field name of the individual role. Defaults to 'role'\"}, 'message_content_field': {'__desc__': \"The field name of the conversation text for the role. Defaults to 'content'\"}, 'separator': {'__desc__': 'The seperator to seperate the conversation texts.'}}, 'output': {'__desc__': 'Configuration for outputting the formatted dataset.', 'return_only_messages': {'__desc__': \"Whether to only keep the 'messages' column. Defaults to 'False'\"}}}, 'deduplicate': {'__desc__': None, 'semantic': {'__desc__': 'Configuration for semantic deduplication.', 'column': {'__desc__': \"Name of the column to deduplicate. Defaults to 'messages'\"}, 'threshold': {'__desc__': \"Minimum threshold to consider two messages similar. Defaults to '0.8'\"}, 'cache_embeddings': {'__desc__': \"Whether to cache the embeddings. Defaults to 'false'\"}, 'embeddings_model': {'__desc__': \"Name of the embedding model to use from huggingface. Defaults to 'sentence-transformers/multi-qa-mpnet-base-dot-v1'\"}, 'device': {'__desc__': \"Name of the device to use. Can be one of 'mps', 'cuda', 'npu', 'hpu', 'cpu'. Defaults to 'null'\"}, 'multi_process': {'__desc__': \"Whether to use multiple processing. Use only when the dataset is too large. Defaults to 'false'\"}, 'show_progress': {'__desc__': \"Whether to show the progress of the deduplication status. Defaults to 'true'\"}}}, 'analyze': {'__desc__': None, 'quality': {'__desc__': 'Configuration for qualitative analysis.', 'column_name': {'__desc__': \"Name of the column to check the quality. Defaults to 'messages'\"}, 'categories': {'__desc__': \"List of categories to use. Defaults to 'null'\"}, 'example_messages': {'__desc__': 'Defines the example messages.', 'messages': {'__desc__': None, 'role': {'__desc__': None}, 'content': {'__desc__': None}}}}}, 'save': {'__desc__': None, 'local': {'__desc__': 'Configuration for saving the dataset locally.', 'directory': {'__desc__': \"Directory path to save the dataset. Defaults to 'processed'\"}, 'filetype': {'__desc__': \"Filetype to save the dataset. Can be one of 'csv', 'json' or 'parquet'. Defaults to 'parquet'\"}, 'filename': {'__desc__': 'Filename to save the dataset. If null auto generates a time based filename and saves in parquet.'}}}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from benedict import benedict\n",
    "\n",
    "\n",
    "benedict(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
